<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
    div.padded {
      padding-top: 0px;
      padding-right: 100px;
      padding-bottom: 0.25in;
      padding-left: 100px;
    }
  </style>
<title>Austin Le  |  CS 184</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="style.css" media="screen" />
</head>
<body>
<br />
<h1 align="middle">CS 184: Computer Graphics and Imaging</h1>
  <h1 align="middle">Assignment 1: Rasterizester</h1>
    <h2 align="middle">Austin Le</h2>

    <br><br>

    <div class="padded">

    <h2 align="middle">Overview</h2>
        <p>In this assignment, I implemented a basic rasterizester, capable of drawing and rendering most images to the screen in a basic, but fairly equipped image viewer.</p>

        <p>To start, I implemented simple rasterization of lines and triangles to the screen. Next, I added antialiasing to the single-color triangles supported above by implementing supersampling at rates of 1 (normal), 4, 9, and 16, followed by downsampling. This process is also commonly known as filtering then sampling. Then, I implemented the three basic transform matrices to support translation, rotation, and scaling of images. In addition, I enabled the user to move and resize the viewer, so that they could more closely examine certain parts of the image using their mouse or touchpad. That concludes Act 1 of the assignment, after which we now have the bare bones of a rasterizester.</p>

        <p>In Act 2, I introduced barycentric coordinates in order to support interpolation within Color and Texture triangles and thus later allow for intricate texture mapping. With this, my rasterizester is then able to support multi-color triangles by performing basic sampling from a Color triangle. Then, I implemented pixel sampling in order to support texture mapping from Texture triangles. Here, I use barycentric coordinates in order to retrieve either the nearest texel in a texture map or perform bilinear sampling to obtain a smoother overall texturing in the image. At this point in time, my rasterizester samples textures only from level zero mipmaps. To further augment my texture mapping, I then implemented level sampling in mipmaps in order to support levels besides the default 0. Depending on the barycentric coordinates of the pixel to be textured, I compute the appropriate mipmap level from which to sample textures from, thus achieving even better texturing in the resulting image. In addition to performing nearest-level mipmap sampling, I can also perform a linear level mipmap sampling, in which the rasterizester does a linear interpolation between the two most applicable mipmap levels to return an even better, "averaged" texture.</p>

        <p>After implementing the above features of a basic rasterizester in two acts, I rendered my own interesting work of art by programmatically generating my own .svg file from scratch. This image is depicted at the bottom of this write-up in Part 8.</p>

    <h2 align="middle">Part 1: Rasterizing Lines</h2>
        <p>In Part 1, I filled in DrawRend::rasterize_line by implementing <a href="http://www.cs.helsinki.fi/group/goa/mallinnus/lines/bresenh.html">Bresenham's algorithm</a> to rasterize lines onto the screen. Unfortunately, the most basic form if Bresenham's algorithm only works correctly for drawing lines in a single octent of a 2-D plane, namely where the slope is between 0 and 1 and the x- and y- coordinates are both positive. An initial, hopeful attempt to use Bresenham's algorithm to produce the desired radial image failed miserably, as shown below.</p>
        <div align="middle">
            <table style="width=100%">
                <tr>
                    <img src="images/part1-issue.png" align="middle"/>
                    <figcaption align="middle">The above image is an example of mapping and unmapping done incorrectly when applying Bresenham's algorithm to draw lines.</figcaption>
                </tr>
            </table>
        </div>
        <p>Note that <em>only</em> the lines in the first octent (bottom right, due to the way x- and y- coordinates are done such that (0, 0) is the top left and (width, height) is the bottom right) are properly drawn to the screen. The lines in the adjacent octents are tightly drawn together with incorrect spacing and lengths, and lines in any of the other remaining 5 octents are non-existent. In addition, only the top line of the containing box is drawn, while the other 3 boundaries to the left, right, and bottom are non-existent.</p>

        <p>To get around Bresenham's algorithm's single-octent limitations, I mapped every one of the other 7 octents into the first octent, computed the pixels to color in on the line, and then re-mapped those pixels back into their original octent. This resulted in 8 different cases in my rasterize_line code. The table below illustrates the mapping and inverse mapping I applied to each octent.</p>

        <div align="middle">
            <table style="width=100%" border="1px" cellpadding="10px">
              <tr>
                  <td>
                      <p>Octent 1</p>
                  </td>
                  <td>
                      <p>Map to Octent 1</p>
                      <p>(x, y) -> (x, y)</p>
                  </td>
                  <td>
                      <p>Map back to Octent 1</p>
                      <p>(x, y) -> (x, y)</p>
                  </td>
              </tr>
              <tr>
                  <td>
                      <p>Octent 2</p>
                  </td>
                  <td>
                      <p>Map to Octent 1</p>
                      <p>(x, y) -> (y, x)</p>
                  </td>
                  <td>
                      <p>Map back to Octent 2</p>
                      <p>(x, y) -> (y, x)</p>
                  </td>
              </tr>
              <tr>
                  <td>
                      <p>Octent 3</p>
                  </td>
                  <td>
                      <p>Map to Octent 1</p>
                      <p>(x, y) -> (y, -x)</p>
                  </td>
                  <td>
                      <p>Map back to Octent 3</p>
                      <p>(x, y) -> (-y, x)</p>
                  </td>
              </tr>
              <tr>
                  <td>
                      <p>Octent 4</p>
                  </td>
                  <td>
                      <p>Map to Octent 1</p>
                      <p>(x, y) -> (-x, y)</p>
                  </td>
                  <td>
                      <p>Map back to Octent 4</p>
                      <p>(x, y) -> (-x, y)</p>
                  </td>
              </tr>
              <tr>
                  <td>
                      <p>Octent 5</p>
                  </td>
                  <td>
                      <p>Map to Octent 1</p>
                      <p>(x, y) -> (-x, -y)</p>
                  </td>
                  <td>
                      <p>Map back to Octent 5</p>
                      <p>(x, y) -> (-x, -y)</p>
                  </td>
              </tr>
              <tr>
                  <td>
                      <p>Octent 6</p>
                  </td>
                  <td>
                      <p>Map to Octent 1</p>
                      <p>(x, y) -> (-y, -x)</p>
                  </td>
                  <td>
                      <p>Map back to Octent 3</p>
                      <p>(x, y) -> (-y, -x)</p>
                  </td>
              </tr>
              <tr>
                  <td>
                      <p>Octent 7</p>
                  </td>
                  <td>
                      <p>Map to Octent 1</p>
                      <p>(x, y) -> (-y, x)</p>
                  </td>
                  <td>
                      <p>Map back to Octent 7</p>
                      <p>(x, y) -> (y, -x)</p>
                  </td>
              </tr>
              <tr>
                  <td>
                      <p>Octent 8</p>
                  </td>
                  <td>
                      <p>Map to Octent 1</p>
                      <p>(x, y) -> (x, -y)</p>
                  </td>
                  <td>
                      <p>Map back to Octent 8</p>
                      <p>(x, y) -> (x, -y)</p>
                  </td>
              </tr>
            </table>
        </div>

        <p>After performing the mapping and unmapping operations correctly for each of the eight octents in order to use Bresenham's algorithm in every octent, I was able to successfully render the desired image.</p>

        <div align="middle">
            <table style="width=100%">
                <tr>
                    <img src="images/part1.png" align="middle"/>
                    <figcaption align="middle">The above image is an example of line rasterization properly implemented using Bresenham's algorithm.</figcaption>
                </tr>
            </table>
        </div>


    <h2 align="middle">Part 2: Rasterizing single-color triangles</h2>
        <p>Describe what you did in Part 2. Show your result here. Explain any bugs you had to work through, with pictures if possible. Explain any special optimizations you did beyond simple bounding box triangle rasterization, with a timing comparison table (we suggest using the c++ clock() function around the svg.draw() command in DrawRend::redraw() to compare millisecond timings with your various optimizations off and on).</p>

        <p>In Part 2, I implemented a simple rasterization algorithm in DrawRend::rasterize_triangle. To do so, I determined the bounding box of the triangle by computing the minimum and maximum x- and y- coordinates for the three vertices passed into the method. Then, for each pixel within the bounding box, using the centers for computation (i.e. (x + 0.5, y + 0.5) for integers x and y), I determined whether or not the pixel was covered by the triangle.</p>

        <p>Instead of using the three line tests as discussed in lecture 2, I used barycentric coordinates to determine whether or not a pixel was covered by the triangle. If any of the three barycentric coordinates, alpha, beta, and gamma were negative, then the pixel was outside of the triangle and thus ignored. Otherwise, I would call DrawRend::rasterize_point to render the pixel, after performing alpha blending with the previous RGBA values.</p>

        <p>Pixels on the edge or vertex of a triangle (e.g. one or more barycentric coordinates were 0) were also colored in using DrawRend::rasterize_point. Originally, I ignored the special case of edges and vertices, so I ended up with an image of a dragon that had "cracks" wherever the edges and vertices existed, as seen below.</p>

        <div align="middle">
            <table style="width=100%">
                <tr>
                    <img src="images/part2-bug.png" align="middle"/>
                    <figcaption align="middle">The above image is an example of forgetting to include pixels that lie on the edge or vertex of a triangle.</figcaption>
                </tr>
            </table>
        </div>

        <p>The above bug was due to checking only that the barycentric coordinates were positive before rendering the corresponding pixel. To resolve this bug, I made sure to also include pixels for which one of more barycentric coordinates were 0 (which indicated they were an edge or vertex pixel). However, I did not implement special edge rules to prevent the renderer from rendering the same pixel more than once, in the case that multiple triangles in the image shared the same edge or vertex.</p>

        <div align="middle">
            <table style="width=100%">
                <tr>
                    <img src="images/part2.png" align="middle"/>
                    <figcaption align="middle">The above image is an example of a properly implemented single-color triangle rasterization algorithm.</figcaption>
                </tr>
            </table>
        </div>

    <h2 align="middle">Part 3: Antialiasing triangles</h2>
        <p>In Part 3, I generalized the algorithm used to rasterize triangles in Part 2 by making the code within DrawRend:rasterize_triangle take into consideration the value of the global variable sample_rate. Depending on the sample_rate, I would take different size steps and start at a different pixel offset in order to properly perform supersampling of each pixel. Previously, each pixel would correspond to 4 values in the framebuffer (sample rate 1), representing the R, G, B, and A values, respectively. However, with greater sample rates, we would require more values to represent each pixel, since we will taking more than one sample per pixel.</p>

        <p>To facilitate this, I introduced a new buffer called ss_framebuffer ("supersampled frame buffer") into drawrend.h that would store sample_rate times as many values as the original framebuffer. For instance, where every 4 values corresponded to one pixel with sample rate 1, sample rate 4 would mean every 16 value chunk of the ss_framebuffer corresponds to one pixel, and so on. For each supersample, I would again use barycentric coordinates to determine whether or not is was within the triangle and should be rendered. If so, I would then write it off into the ss_framebuffer using a modified version of DrawRend::rasterize_point. After all of the relevant pixels are considered, the DrawRend::resolve method is called, at which point I extract the appropriate size chunk of values (depending on the value of sample_rate), average out their RGBA values, and write them into the corresponding index of the original framebuffer to be rendered.</p>

        <p>However, filling up the ss_framebuffer proved a little more challenging than anticipated, as I ended up introducing a bug in my code that caused my images to fade and "smear" downwards and to the right. As I increased the sampling rate, the effect became more dramatic.</p>

        <div align="middle">
            <table style="width=100%">
                <tr>
                    <img src="images/part3-bug.png" align="middle"/>
                    <figcaption align="middle">The above image is an example of failing to correctly fill and resolve a supersampled frame buffer while trying to antialias triangles.</figcaption>
                </tr>
            </table>
        </div>

        <p>This bug was especially difficult to find since I was definitely leaving chunks of 4 bytes (a set of RGBA values) in the supersampled framebuffer at their default value of 255, for pixels that I had determined to be outside of the triangle. However, it turned out that while I was correctly writing "nothing" into a supersample of the ss_framebuffer, it was the <em>wrong</em> supersample. The root of this bug boiled down to a novice mistake in control flow and when to (and when not to) increment counters.</p>

        <p>For instance, rather than having a set of 4 supersamples be [VALID, VALID, BLANK, VALID] or [VALID, BLANK, VALID, VALID], I would always have the "blank" pixels come in at the end of the set. So, while I had the correct number of "blank" pixels, they were written into the wrong places. At first, I figured that this shouldn't affect the rendered image, since the average of 4 Color objects (done in DrawRend::resolve) is the same no matter what order the 4 objects were. However, this is an incorrect assumption, since alpha-blending is also performed at a supersample level, which would most definitely be affected due to incorrect ordering of the supersamples.</p>

        <p>After resolving the above counter incrementing failure, my images were properly supersampled and my triangles looked a lot smoother at high sampling rates! In the images below, I've demonstrated the relative improvements between sampling rates of 1, 4, 9, and 16.</p>

        <div align="middle">
            <table style="width=100%" border="1px" cellpadding="10px">
                <tr>
                    <td>
                        <p>Sampling rate: 1</p>
                    </td>
                    <td>
                        <img src="images/part3-1.png" align="middle"/>
                    </td>
                </tr>
                <tr>
                    <td>
                        <p>Sampling rate: 4</p>
                    </td>
                    <td>
                        <img src="images/part3-2.png" align="middle"/>
                    </td>
                </tr>
                <tr>
                    <td>
                        <p>Sampling rate: 9</p>
                    </td>
                    <td>
                        <img src="images/part3-3.png" align="middle"/>
                    </td>
                </tr>
                <tr>
                    <td>
                        <p>Sampling rate: 16</p>
                    </td>
                    <td>
                        <img src="images/part3-4.png" align="middle"/>
                    </td>
                </tr>
            </table>
        </div>

    <h2 align="middle">Part 4: Transforms</h2>
        <p>Describe what you did in Part 4. Show your result here. Explain any bugs you had to work through, with pictures if possible. Describe the new svg file you created, and show the rasterized result. Explain the reasoning behind your use of the transform stack in your new file. If you added any extra features to the GUI, describe them, and depict the result if it is visualizable (e.g. if you add rotation controls).</p>

        <p>Part 4 consisted of a few different parts. The first part involved implementing the 3x3 matrices used for the translation, rotation, and scaling of images. These are 3x3 matrices because we use homogenous coordinates to transform our 2-dimensional vectors. Coding these up was fairly straightforward, since we already had a reference for what the translation, rotation, and scaling matrices should look like, thanks to the <a href="https://developer.mozilla.org/en-US/docs/Web/SVG/Attribute/transform" target="_blank">SVG spec</a>.</p>

        <p>The second part involved implementing DrawRend::move_view, which turned out to be more easily and intuitively implemented by extracting the previous SVG space values, then updating them by calling the provided DrawRend::set_view. The values x, y, and span were all encoded into the final column of the svg_to_ndc matrix and could be "reverse-engineered" from how they were used in DrawRend::set_view. When applying the changes dx, dy, and zoom, I decided to subtract dx and dy from the previous x and y values and to have zoom be multiplied to the previous span. These decisions mapped to the way I am more used to and comfortable using my mousepad to navigate and zoom in and out of interactive screens.</p>

        <p>Lastly, I applied the transform matrices implemented in the first part by creating four of my own SVG files that involved some transform stack of at least two matrices deep. The first two SVGs are paired together with a simple transform stack of two matrices: a rotation and a translation. I selected this pair of transforms since the ordering is clearly impactful on the resulting image. Similarly, the last two SVGs are also paired together in that they share the same 4 transforms, just in a different ordering. In this case, there are 4 transforms, which include a rotation, a scaling, and 2 translations. The same reasoning applies, but this example also demonstrates that where you place the scaling transform is equally significant.</p>

        <p>The resulting PNGs are depicted below.</p>

        <div align="middle">
            <table style="width=100%" border="1px" cellpadding="10px">
                <tr>
                    <td>
                        <p>
                            <ol>
                                <li>Rotate 10 degrees clockwise about (200, 200)</li>
                                <li>Translate 50 pixels down</li>
                            </ol>
                        </p>
                    </td>
                    <td>
                        <img src="images/part4-1.png" align="middle"/>
                    </td>
                </tr>
                <tr>
                    <td>
                      <p>
                          <ol>
                              <li>Translate 50 pixels down</li>
                              <li>Rotate 10 degrees clockwise about (200, 200)</li>
                          </ol>
                      </p>
                    </td>
                    <td>
                        <img src="images/part4-2.png" align="middle"/>
                    </td>
                </tr>
                <tr>
                    <td>
                        <p>
                            <ol>
                                <li>Rotate 45 degrees counterclockwise about (300, 300)</li>
                                <li>Translate 50 units right</li>
                                <li>Translate 200 units left</li>
                                <li>Scale by a factor of 2</li>
                            </ol>
                        </p>
                    </td>
                    <td>
                        <img src="images/part4-3.png" align="middle"/>
                    </td>
                </tr>
                <tr>
                    <td>
                        <p>
                            <ol>
                                <li>Scale by a factor of 2</li>
                                <li>Translate 50 units right</li>
                                <li>Rotate 45 degrees counterclockwise about (300, 300)</li>
                                <li>Translate 200 units left</li>
                            </ol>
                        </p>
                    </td>
                    <td>
                        <img src="images/part4-4.png" align="middle"/>
                    </td>
                </tr>
            </table>
        </div>

    <h2 align="middle">Part 5: Barycentric coordinates</h2>
        <p>Barycentric coordinates are essentially a coordinate system for triangles, defined by a set of 3 values [alpha, beta, gamma]. These values are relative to the vertices of a specific triangle, so barycentric coordinates are attached directly to the triangle from which they are derived. Each of the 3 values corresponds to one of the 3 vertices of the triangle, and essentially tells us how heavily that vertex weighs into a given point. This value can be position, but could also be values such as color, as it is used here in Part 5. It is important to note that <pre align="middle">alpha + beta + gamma = 1</pre> always holds true, and any point within the triangle (or even those outside of the triangle) can be defined as <pre align="middle">V = alpha * A + beta * B + gamma * C</pre>where A, B, C are the vertices of the triangle (which could be coordinates, color values, etc.).</p>

        <p>Barycentric coordinates are also very useful for interpolation between the 3 vertices of a triangle. For example, consider a triangle that has a pure red (255, 0, 0) vertex, a pure green (0, 255, 0) vertex, and a pure blue (0, 0, 255) vertex. If we interpolate between these three vertices using barycentric coordinates, we get the following color triangle. Notice how as we move from one vertex to another, the color gradually and smoothly shifts from one to the other, moving along the color spectrum of RGB values. In the center, we have an equal balance of R, G, and B values.</p>

        <div align="middle">
            <table style="width=100%">
                <tr>
                    <img src="images/part5-example.png" align="middle"/>
                    <figcaption align="middle">A color triangle with a red vertex, a green vertex, and a blue vertex, with all other pixels within the triangle interpolated from just those 3 solid-colored vertices.</figcaption>
                </tr>
            </table>
        </div>

        <p>To support multi-color triangles being rasterized onto the screen, I augmented DrawRend::rasterize_triangle in drawrend.cpp and implemented ColorTri::color in svg.cpp. In order to do so, I built off of the barycentric coordinates I had already computed from Part 2 in order to interpolate the correct Color values from the provided ColorTri argument in DrawRend::rasterize_triangle. If the Triangle pointer passed in was non-NULL, I request a Color object from it by passing in the barycentric coordinates in a 2-dimensional vector [alpha, beta]. Then, within the ColorTri::color method, I use the provided alpha and beta to compute gamma, and then interpolate to get the desired Color by using the equation described above.</p>

        <div align="middle">
            <table style="width=100%">
                <tr>
                    <img src="images/part5.png" align="middle"/>
                    <figcaption align="middle">The above image is an example of properly interpolating colors from a ColorTri object using barycentric coordinates.</figcaption>
                </tr>
            </table>
        </div>

    <h2 align="middle">Part 6: Pixel sampling for texture mapping</h2>
        <p>In Part 6, I implemented pixel sampling for texture mapping using mipmaps at level 0 (highest texture resolution). For this assignment, we used two different pixel sampling methods: nearest and bilinear, which could be toggled in the display.</p>

        <p>With nearest pixel sampling, we take the barycentric coordinates of the pixel being colored, convert it into uv coordinates (texture space), and then access the appropriate texel in the level 0 mipmap to get the desired Color. The texel taken from the texture map is simply the nearest one (obtained by flooring the u- and v- coordinates to the closest integer), as suggested by the same of this sampling method. The pixel sampling method is fast, but generally produces rougher images, since the texels used in adjacent screen-space pixels may not be as close to each other in texture space.</p>

        <p>Bilinear pixel sampling, on the other hand, is a little more complicated. For the most part, the process is the same as nearest pixel sampling, up until we select the texel from the texture map. Instead of selecting the closest one by flooring the u- and v- coordinates, we select the four closest surrounding texels. This is dependent on exactly where we are sampling the texture map, more specifically, which quadrant of the texel the sample is being taken from. As a result, there are four potentially different sets of 4 texels we could use in our bilinear sampling. After selecting the 4, we perform a series of three linear interpolations to get a bilinear interpolation, which essentially represents a 2-dimensional "average" of the four surrounding texels' Color values. This "average" is what we return to be used as the Color for the original pixel. This method is a little more expensive, since we have to access four times as many values as well as perform three linear interpolations, but generally results in smoother images, since the textures have been "averaged" out by texels close to the desired texel.</p>

        <p>As alluded to in the above two paragraphs explaining the different pixel sampling methods, there will be a large difference in the quality of the resulting image when the triangles being textured are "farther away" in the image. The frequency in this area is typically higher and thus more difficult to texture, since adjacent pixels here would map to texels that are much farther away from each other in the texture map (i.e. their (u, v) coordinates are farther apart than their corresponding pixel (x, y) coordinates). In this scenario, nearest pixel sampling performs poorly, while bilinear pixel sampling somewhat negates the issue due to its linear interpolation causing an "averaging" of textures that makes the resulting image smoother. On the other hand, if we are dealing with a relatively "large" object that is "closer" to the screen, then adjacent pixels typically map to more or less adjacent texels in the texture space. Thus, there is no real noticeable difference between taking an average of the four surrounding texels and the nearest texel itself, since the results are pretty much the same. As a result, we don't see much of an improvement with either one.</p>

        <p>Below are four images comparing the differences between nearest pixel sampling at sample rate 1, bilinear pixel sampling at sample rate 1, nearest pixel sampling at sample rate 16, and bilinear pixel sampling at sample rate 16.</p>

        <p>At sample rate 1, note that bilinear sampling has a significant improvement over nearest-pixel sampling in how the white longitudal line and red latitude line are rendered. Both lines are better smoothed out over several pixels and more symmetrical in bilinear sampling.</p>

        <p>At sample rate 16, even nearest-pixel sampling performs fairly well and is comparable to bilinear sampling at sample rate 1. However, we can still see an improvement when we switch to bilinear sampling at sample rate 16, as the red latitude line is still better smoothed out in its RGBA values as we move vertically along the y-axis in screen space.</p>

        <div align="middle">
            <table style="width=100%" border="1px" cellpadding="10px">
                <tr>
                    <td>
                        <p>Sampling rate: 1</p>
                        <p>Nearest pixel sampling (P_NEAREST)</p>
                    </td>
                    <td>
                        <img src="images/part6-nearest-1.png" align="middle"/>
                    </td>
                </tr>
                <tr>
                    <td>
                        <p>Sampling rate: 1</p>
                        <p>Bilinear sampling (P_BILINEAR)</p>
                    </td>
                    <td>
                        <img src="images/part6-bilinear-1.png" align="middle"/>
                    </td>
                </tr>
                <tr>
                    <td>
                        <p>Sampling rate: 16</p>
                        <p>Nearest pixel sampling (P_NEAREST)</p>
                    </td>
                    <td>
                        <img src="images/part6-nearest-16.png" align="middle"/>
                    </td>
                </tr>
                <tr>
                    <td>
                        <p>Sampling rate: 16</p>
                        <p>Bilinear sampling (P_BILINEAR)</p>
                    </td>
                    <td>
                        <img src="images/part6-bilinear-16.png" align="middle"/>
                    </td>
                </tr>
            </table>
        </div>

    <h2 align="middle">Part 7: Level sampling with mipmaps for texture mapping</h2>
        <p>In Part 7, I implemented level sampling with mipmaps, so that texel sampling from Part 6 would not be limited to only level 0 mipmaps. Thus, we can access a more appropriate mipmap level, as necessary, in order to better texture different pixels in screen space. This helps us solve some of the texturing issues we noticed in Part 6, due to objects in the screen being "farther away" or "closer" (the frequency of objects in the image).</p>

        <p>To implement level sampling, I augmented DrawRend::rasterize_triangle to also compute the barycentric coordinates of the (x + 1, y) and (x, y + 1) pixels. From there, I updated TexTri::color to compute du and dv vectors, which represented how far in uv-space (texture space) we have to move in order to get to the next texel for adjacent pixels in screen space. Based on the du and dv vectors, we can compute L within Texture::sample. L represents the distance travelled in texture space to reach the next desired texel. From there, we can then compute D, which is the level of the mipmap we should use.</p>

        <p>Besides level zero sampling, we can also sample the nearest level (as computed above) or we can perform a linear level sampling, which takes the two adjacent levels, D and D + 1, and does a linear interpolation between the two in order to get an even better Color. When we choose linear level sampling (L_LINEAR) along with bilinear pixel sampling (P_BILINEAR) from above, we are essentially performing trilinear texture sampling, which involves a linear interpolation of two bilinear samples (each of which also involved a few linear interpolations).</p>

        <p>To help illustrate level sampling with mipmaps in conjunction with the pixel sampling methods implemented in Part 6, I selected a .png image of a popular internet meme commonly referred to as "pepe the frog". Using this image as a texture for a .svg file, I experimented with the four possible combinations of [L_ZERO, L_NEAREST] x [P_NEAREST, P_BILINEAR] in texture sampling and have included screenshots of the results below.</p>

        <p>For both level zero and nearest level sampling, we notice that bilinear pixel sampling always outperforms nearest-pixel sampling, regardless of which level of the mipmap we are using. The lines are better smoothed out and the pixel colors don't change as abruptly. Between level zero and nearest level sampling, we notice a slight improvement when using nearest level sampling; however, the difference is very small with this particular image, since nearest level sampling commonly chose level 0. In general, the levels will come into play when we have different depths of objects in our image ("farther away" or "closer" to the screen, as mentioned before), since objects farther away in the image will want to employ higher-level mipmaps. Those higher-level mipmaps contain more downsampled textures more suited to objects whose frequency is higher as a result of being "farther away" in the image.</p>

        <div align="middle">
            <table style="width=100%" border="1px" cellpadding="10px">
                <tr>
                    <td>
                        <p>Level 0 mipmap (L_ZERO)</p>
                        <p>Nearest pixel sampling (P_NEAREST)</p>
                    </td>
                    <td>
                        <img src="images/part7-zero-nearest.png" align="middle"/>
                    </td>
                </tr>
                <tr>
                    <td>
                        <p>Level 0 mipmap (L_ZERO)</p>
                        <p>Bilinear sampling (P_BILINEAR)</p>
                    </td>
                    <td>
                        <img src="images/part7-zero-bilinear.png" align="middle"/>
                    </td>
                </tr>
                <tr>
                    <td>
                        <p>Nearest level mipmap (L_NEAREST)</p>
                        <p>Nearest pixel sampling (P_NEAREST)</p>
                    </td>
                    <td>
                        <img src="images/part7-nearest-nearest.png" align="middle"/>
                    </td>
                </tr>
                <tr>
                    <td>
                        <p>Nearest level mipmap (L_NEAREST)</p>
                        <p>Bilinear sampling (P_BILINEAR)</p>
                    </td>
                    <td>
                        <img src="images/part7-nearest-bilinear.png" align="middle"/>
                    </td>
                </tr>
            </table>
        </div>

    <h2 align="middle">Part 8: My drawing</h2>
        <div align="middle">
            <table style="width=100%">
                <tr>
                    <img src="images/competition.png" align="middle"/>
                    <figcaption align="middle">A Sierpinski triangle, whose textures are sampled from an image of a popular internet meme commonly known as "doge".</figcaption>
                </tr>
            </table>
        </div>

        <p>My drawing is inspired by the Sierpinski triangle, which involves recursively drawing smaller triangles branching off of the original, main triangle. For this drawing, I selected an image of a shiba, a type of dog popularized by a common internet meme usually referred to as "doge". I used this image as the texture from which all of the TexTris in my image would sample from.</p>

        <p>In order to create the image, I wrote a Python script to recursively generate the TexTri objects needed to produce this .svg file. The Python script begins by computing the coordinates of the three vertices of the main, original triangle (which is also the largest and located in the center of the resulting image). Then, it calls a recursive function to repeatedly generate lines of SVG code with recursively smaller and smaller triangles. The coordinates of the vertices of these smaller triangles can be relatively simply computed based on the coordinates of the previous triangle. The code continues to recursively call itself until it reaches a maximum depth MAX_DEPTH, defined at the top of the Python script.</p>

        <p>This Python script can be found in src/generate_svg.py and can be run from the root project directory with the command "python3 src/generate_svg.py". The script then creates a .svg file located at svg/my_examples/generated.svg, which can then be rendered from the build/ directory using the command "./rasterizester ../svg/my_examples/generated.svg".</p>
</div>
</body>
</html>
